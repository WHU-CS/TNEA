{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email-Eu 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def subgraphs_cons_for_Email_Eu(file, split):\n",
    "    fr = open(file)\n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    for line in fr.readlines():\n",
    "        linestr = line.strip().split(' ')\n",
    "        link = [int(linestr[0]), int(linestr[1]), int(linestr[2])]\n",
    "        links.append(link)\n",
    "    \n",
    "    subgraphs = {}\n",
    "    # 统计前789天的数据\n",
    "    for i in range(798):\n",
    "        subgraphs[i] = []\n",
    "    \n",
    "    for line in links:\n",
    "        week = int(line[2] / (3600*24*split))\n",
    "        if week < 798:\n",
    "            subgraphs[week].append([line[0], line[1]])\n",
    "    \n",
    "    # 输出subgraphs\n",
    "    for key in subgraphs.keys():\n",
    "        if len(subgraphs[key]) != 0:\n",
    "            fr = open('new_sub/email_eu_sub/' + str(key) + '.txt', 'w')\n",
    "            for line in subgraphs[key]:\n",
    "                fr.write(str(line[0]) + '\\t' + str(line[1]) + '\\n')\n",
    "            fr.close()\n",
    "            \n",
    "    return subgraphs\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按时间划分子图\n",
    "sub_graphs = subgraphs_cons_for_Email_Eu('../dataset/email-Eu.txt', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ？from tqdm import tqdm\n",
    "def TTM_count(sub_graphs, max_node):\n",
    "    \n",
    "    for key in range(len(sub_graphs)-1):#sub_graphs.keys():\n",
    "        if len(sub_graphs[key]) > 100 and len(sub_graphs[key+1] )> 100:\n",
    "            ad_matrix1 = np.zeros([max_node, max_node])\n",
    "            ad_matrix2 = np.zeros([max_node, max_node])\n",
    "            \n",
    "            for line in sub_graphs[key]:\n",
    "                ad_matrix1[line[0], line[1]] = 1\n",
    "            for line in sub_graphs[key+1]:\n",
    "                ad_matrix2[line[0], line[1]] = 1\n",
    "            \n",
    "            TTM = np.zeros((64, 64))\n",
    "            for line in sub_graphs[key]:\n",
    "                node_a = line[0]\n",
    "                node_b = line[1]\n",
    "                for node_c in range(max_node):\n",
    "                    node_list = [node_a, node_b, node_c]\n",
    "                    node_list.sort()\n",
    "                    id1 = int(ad_matrix1[node_list[0],node_list[2]] + ad_matrix1[node_list[1],node_list[2]]*2 + ad_matrix1[node_list[2],node_list[0]]*4 + ad_matrix1[node_list[1],node_list[0]]*8 + ad_matrix1[node_list[2],node_list[1]] *16 + ad_matrix1[node_list[0],node_list[1]]*32)\n",
    "                    id2 = int(ad_matrix2[node_list[0],node_list[2]] + ad_matrix2[node_list[1],node_list[2]]*2 + ad_matrix2[node_list[2],node_list[0]]*4 + ad_matrix2[node_list[1],node_list[0]]*8 + ad_matrix2[node_list[2],node_list[1]] *16 + ad_matrix2[node_list[0],node_list[1]]*32)\n",
    "                    TTM[id1, id2] += 1\n",
    "            TTM[0,0] = 1\n",
    "            TTM = TTM / TTM.sum(axis=1).reshape((-1,1))\n",
    "            \n",
    "            \n",
    "            \n",
    "#             ofr.write('TTM of snapshot '+ str(key) + ' to ' + 'snapshot' + str(key+1) + '\\n')\n",
    "            ofr = open('./TTMs/art_TTM' + str(key) + '_'+ str(key+1) + '.txt', 'w')\n",
    "            for line in TTM:\n",
    "                ofr.write(str(line) + '\\n')\n",
    "            ofr.close()\n",
    "\n",
    "\n",
    "  \n",
    "                           \n",
    "                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CloMsg数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def subgraphs_cons_for_cloM(file, split):\n",
    "    fr = open(file)\n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    for line in fr.readlines():\n",
    "        linestr = line.strip().split(' ')\n",
    "        link = [int(linestr[0])-1, int(linestr[1])-1, int(linestr[2])]\n",
    "        links.append(link)\n",
    "    \n",
    "    linkN = np.array(links)\n",
    "    max_time = linkN.max(axis=0)[2]\n",
    "    min_time = linkN.min(axis=0)[2]\n",
    "    \n",
    "    \n",
    "    subgraphs = {}\n",
    "    # 统计前789天的数据\n",
    "    for i in range(28):\n",
    "        subgraphs[i] = []\n",
    "    \n",
    "    for line in links:\n",
    "        week = int((line[2] - min_time)/ (3600*24*split))\n",
    "        if week < 28:\n",
    "            subgraphs[week].append([line[0], line[1]])\n",
    "    \n",
    "    # 输出subgraphs\n",
    "    for key in subgraphs.keys():\n",
    "        if len(subgraphs[key]) != 0:\n",
    "            fr = open('new_sub/col_ms_sub/' + str(key) + '.txt', 'w')\n",
    "            for line in subgraphs[key]:\n",
    "                fr.write(str(line[0]) + '\\t' + str(line[1]) + '\\n')\n",
    "            fr.close()\n",
    "            \n",
    "    return subgraphs\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graphs = subgraphs_cons_for_cloM('../dataset/CollegeMsg.txt' , 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def subgraphs_cons_for_enron(file, split):\n",
    "    fr = open(file)\n",
    "    \n",
    "    links = []\n",
    "    node_map = set()\n",
    "    \n",
    "    \n",
    "    for line in fr.readlines():\n",
    "        linestr = line.strip().split(' ')\n",
    "        \n",
    "        time = int(linestr[3])\n",
    "        \n",
    "        if time >= 978278401 and time <= 1009814399:\n",
    "            link = [int(linestr[0])-1, int(linestr[1])-1, int(linestr[3])]\n",
    "            links.append(link)\n",
    "            node_map.add(int(linestr[0])-1)\n",
    "            node_map.add(int(linestr[1])-1)\n",
    "    \n",
    "    n_map = {}\n",
    "    \n",
    "    for i, ele in enumerate(node_map):\n",
    "        n_map[ele] = i\n",
    "    \n",
    "    new_links = []\n",
    "    \n",
    "    for link in links:\n",
    "        if n_map[link[0]] <= 2114 and n_map[link[1]] <= 2114:\n",
    "            node_a = n_map[link[0]]\n",
    "            node_b = n_map[link[1]]\n",
    "            new_links.append([node_a, node_b, link[2]])\n",
    "\n",
    "    \n",
    "    linkN = np.array(new_links)\n",
    "    max_time = linkN.max(axis=0)[2]\n",
    "    min_time = linkN.min(axis=0)[2]\n",
    "    \n",
    "    \n",
    "    subgraphs = {}\n",
    "    # 统计前789天的数据\n",
    "    for i in range(53):\n",
    "        subgraphs[i] = []\n",
    "    \n",
    "    for line in linkN:\n",
    "        week = int((line[2] - min_time)/ (3600*24*split))\n",
    "        if week < 53:\n",
    "            subgraphs[week].append([line[0], line[1]])\n",
    "    \n",
    "    # 输出subgraphs\n",
    "    for key in subgraphs.keys():\n",
    "        if len(subgraphs[key]) != 0:\n",
    "            fr = open('new_sub/enron_sub/' + str(key) + '.txt', 'w')\n",
    "            for line in subgraphs[key]:\n",
    "                fr.write(str(line[0]) + '\\t' + str(line[1]) + '\\n')\n",
    "            fr.close()\n",
    "            \n",
    "    return subgraphs\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graphs = subgraphs_cons_for_enron('../dataset/out.enron' , 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def subgraphs_cons_for_facebook(file, split):\n",
    "    fr = open(file)\n",
    "    \n",
    "    links = []\n",
    "    node_map = set()\n",
    "    \n",
    "    \n",
    "    for line in fr.readlines():\n",
    "        linestr = line.strip().split('\\t')\n",
    "        \n",
    "        time = int(linestr[2])\n",
    "        \n",
    "        if time >= 1199116801 and time <= 1229875199:\n",
    "            link = [int(linestr[0])-1, int(linestr[1])-1, int(linestr[2])]\n",
    "            links.append(link)\n",
    "            node_map.add(int(linestr[0])-1)\n",
    "            node_map.add(int(linestr[1])-1)\n",
    "    \n",
    "    n_map = {}\n",
    "    \n",
    "    for i, ele in enumerate(node_map):\n",
    "        n_map[ele] = i\n",
    "    \n",
    "    new_links = []\n",
    "    \n",
    "    for link in links:\n",
    "        if n_map[link[0]] < 5111 and n_map[link[1]] <5111:\n",
    "            node_a = n_map[link[0]]\n",
    "            node_b = n_map[link[1]]\n",
    "            new_links.append([node_a, node_b, link[2]])\n",
    "\n",
    "    \n",
    "    linkN = np.array(new_links)\n",
    "    max_time = linkN.max(axis=0)[2]\n",
    "    min_time = linkN.min(axis=0)[2]\n",
    "    \n",
    "    \n",
    "    subgraphs = {}\n",
    "    # \n",
    "    for i in range(12):\n",
    "        subgraphs[i] = []\n",
    "    \n",
    "    for line in linkN:\n",
    "        week = int((line[2] - min_time)/ (3600*24*split))\n",
    "        if week < 12:\n",
    "            subgraphs[week].append([line[0], line[1]])\n",
    "    \n",
    "    # 输出subgraphs\n",
    "    for key in subgraphs.keys():\n",
    "        if len(subgraphs[key]) != 0:\n",
    "            fr = open('new_sub/facebook_sub/' + str(key) + '.txt', 'w')\n",
    "            for line in subgraphs[key]:\n",
    "                fr.write(str(line[0]) + '\\t' + str(line[1]) + '\\n')\n",
    "            fr.close()\n",
    "            \n",
    "    return subgraphs\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_graphs = subgraphs_cons_for_facebook('../dataset/facebook-wall.txt' , 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人工网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "file_path = './art_sub/'\n",
    "\n",
    "file_names = os.listdir(file_path)\n",
    "sub_graphs = {}\n",
    "\n",
    "file_names.sort(key = lambda x:int(x.split('.')[0]))\n",
    "\n",
    "for i in range(13):\n",
    "    sub_graphs[i] = []\n",
    "    fr = open('./art_sub/' + file_names[i])\n",
    "    for line in fr.readlines():\n",
    "        arr = line.strip().split('\\t')\n",
    "        node_1 = int(arr[0])\n",
    "        node_2 = int(arr[1])\n",
    "        sub_graphs[i].append([node_1, node_2])\n",
    "        \n",
    "\n",
    "TTM_count(sub_graphs, 200)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
